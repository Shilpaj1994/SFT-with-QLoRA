{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Supervised Fine Tuning\n",
        "\n",
        "- Once the base model (foundation model) is trained for text completion task, it is time for `Post-Training`\n",
        "- It is the step in which the model will get capability of following instructions and conversing\n",
        "- Post-training consists of two steps:\n",
        "    - Supervised Fine Tuning (SFT)\n",
        "    - Preference Fine Tuning (PFT)\n",
        "- Supervised Fine-Tuning (SFT) - Training the model on curated, instruction-based data.\n",
        "- Preference Fine-Tuning (RLHF, DPO, PPO) - Training the model to align better with human preference\n",
        "\n",
        "In order to perform the SFT, there are three approaches:\n",
        "- Full fine tuning\n",
        "- LoRA\n",
        "- QLoRA\n",
        "\n",
        "In this notebook, QLoRA implemented to perform the SFT on phi-2 model using OpenAssistant dataset"
      ],
      "metadata": {
        "id": "gOTpfjQyook7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "nnSmfycwqWsA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myf0fvo9oeCY",
        "outputId": "83d2b445-7594-459d-8b6e-ad4eb2dab40e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m931.6/931.6 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q torch transformers accelerate bitsandbytes datasets peft trl pytorch-lightning tensorboard einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training\n",
        "Train the Phi-2 base model on [OpenAssistant](https://huggingface.co/datasets/OpenAssistant/oasst1?row=0) dataset using QLoRA"
      ],
      "metadata": {
        "id": "ZJh6xD1hKyG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python training.py --max_epochs 1 --no_validation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ypll_WtSbWM",
        "outputId": "d2112397-df0e-474b-8505-aec438ad9731"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-07 07:08:43.033975: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741331323.295344     797 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741331323.366067     797 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-07 07:08:43.936817: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Setting batch size to 1 to save memory\n",
            "Set gradient accumulation to 16\n",
            "Set dataloader workers to 0 (main process only)\n",
            "tokenizer_config.json: 100% 7.34k/7.34k [00:00<00:00, 30.5MB/s]\n",
            "vocab.json: 100% 798k/798k [00:00<00:00, 24.5MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 28.0MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 9.57MB/s]\n",
            "added_tokens.json: 100% 1.08k/1.08k [00:00<00:00, 6.59MB/s]\n",
            "special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 692kB/s]\n",
            "DeepSpeed not available - using standard training\n",
            "Enabling extreme memory saving options...\n",
            "config.json: 100% 735/735 [00:00<00:00, 5.22MB/s]\n",
            "model.safetensors.index.json: 100% 35.7k/35.7k [00:00<00:00, 135MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/5.00G [00:00<01:36, 51.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/5.00G [00:00<01:30, 55.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/5.00G [00:00<00:49, 99.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/5.00G [00:00<00:41, 119MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 105M/5.00G [00:00<00:37, 130MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/5.00G [00:01<00:32, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 157M/5.00G [00:01<00:34, 142MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 189M/5.00G [00:01<00:35, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 220M/5.00G [00:01<00:31, 151MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/5.00G [00:01<00:30, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 262M/5.00G [00:02<00:32, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 283M/5.00G [00:02<00:31, 148MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 315M/5.00G [00:02<00:27, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 346M/5.00G [00:02<00:25, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 367M/5.00G [00:02<00:25, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 388M/5.00G [00:02<00:26, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 409M/5.00G [00:02<00:25, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 440M/5.00G [00:02<00:23, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/5.00G [00:03<00:29, 155MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/5.00G [00:03<00:25, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 514M/5.00G [00:03<00:26, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 535M/5.00G [00:03<00:26, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/5.00G [00:03<00:26, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/5.00G [00:03<00:28, 155MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 619M/5.00G [00:04<00:25, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/5.00G [00:04<00:25, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 671M/5.00G [00:04<00:24, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 692M/5.00G [00:04<00:25, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 724M/5.00G [00:04<00:21, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 755M/5.00G [00:04<00:20, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 786M/5.00G [00:04<00:19, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 818M/5.00G [00:07<02:14, 31.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 839M/5.00G [00:07<01:47, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/5.00G [00:08<01:38, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/5.00G [00:08<01:23, 49.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 902M/5.00G [00:08<01:12, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 923M/5.00G [00:08<01:02, 65.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 954M/5.00G [00:09<00:56, 71.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 975M/5.00G [00:09<00:46, 85.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 996M/5.00G [00:09<00:39, 101MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.02G/5.00G [00:09<00:34, 116MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/5.00G [00:09<00:31, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/5.00G [00:09<00:32, 123MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/5.00G [00:10<00:29, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/5.00G [00:10<00:26, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.12G/5.00G [00:10<00:26, 145MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/5.00G [00:10<00:39, 97.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/5.00G [00:10<00:31, 121MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.20G/5.00G [00:11<00:42, 89.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.22G/5.00G [00:11<00:54, 68.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/5.00G [00:11<01:01, 61.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/5.00G [00:12<00:52, 71.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.27G/5.00G [00:12<00:44, 84.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/5.00G [00:12<00:49, 75.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/5.00G [00:12<01:02, 59.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/5.00G [00:12<00:46, 78.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/5.00G [00:13<00:38, 95.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.35G/5.00G [00:13<00:40, 90.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.37G/5.00G [00:13<00:35, 103MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/5.00G [00:13<00:29, 120MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.42G/5.00G [00:13<00:28, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/5.00G [00:13<00:25, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/5.00G [00:13<00:23, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.49G/5.00G [00:14<00:20, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/5.00G [00:14<00:19, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/5.00G [00:14<00:17, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.56G/5.00G [00:14<00:18, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/5.00G [00:14<00:17, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.61G/5.00G [00:14<00:17, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/5.00G [00:14<00:19, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.66G/5.00G [00:15<00:22, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/5.00G [00:15<00:21, 155MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/5.00G [00:15<00:21, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.72G/5.00G [00:15<00:23, 142MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/5.00G [00:15<00:24, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.76G/5.00G [00:15<00:24, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.78G/5.00G [00:16<00:28, 114MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.80G/5.00G [00:16<00:28, 110MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.82G/5.00G [00:16<00:27, 116MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.85G/5.00G [00:16<00:25, 125MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.87G/5.00G [00:16<00:22, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.89G/5.00G [00:16<00:20, 155MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.92G/5.00G [00:16<00:17, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/5.00G [00:17<00:19, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/5.00G [00:17<00:41, 72.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/5.00G [00:17<00:35, 85.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/5.00G [00:18<00:32, 92.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/5.00G [00:18<00:30, 96.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/5.00G [00:18<00:26, 110MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.07G/5.00G [00:18<00:29, 99.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/5.00G [00:19<00:37, 77.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.11G/5.00G [00:19<00:38, 75.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/5.00G [00:19<00:34, 83.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/5.00G [00:19<00:36, 78.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.18G/5.00G [00:20<00:27, 103MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.20G/5.00G [00:20<00:23, 119MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.22G/5.00G [00:20<00:30, 89.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/5.00G [00:20<00:27, 100MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.26G/5.00G [00:20<00:23, 114MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.29G/5.00G [00:20<00:20, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.32G/5.00G [00:21<00:17, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/5.00G [00:21<00:16, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.36G/5.00G [00:21<00:28, 93.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/5.00G [00:21<00:24, 107MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/5.00G [00:21<00:22, 115MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.42G/5.00G [00:22<00:20, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/5.00G [00:22<00:19, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.46G/5.00G [00:22<00:17, 145MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/5.00G [00:22<00:18, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/5.00G [00:22<00:18, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/5.00G [00:22<00:20, 122MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.56G/5.00G [00:23<00:16, 145MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/5.00G [00:23<00:15, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.60G/5.00G [00:23<00:14, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.62G/5.00G [00:23<00:13, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.64G/5.00G [00:23<00:24, 95.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.66G/5.00G [00:23<00:22, 105MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.69G/5.00G [00:24<00:17, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.73G/5.00G [00:24<00:14, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.76G/5.00G [00:24<00:12, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/5.00G [00:24<00:12, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/5.00G [00:24<00:12, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.82G/5.00G [00:24<00:14, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.84G/5.00G [00:24<00:14, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.86G/5.00G [00:25<00:16, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/5.00G [00:25<00:15, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.90G/5.00G [00:25<00:15, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/5.00G [00:25<00:15, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/5.00G [00:25<00:16, 125MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.97G/5.00G [00:25<00:15, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.00G/5.00G [00:26<00:12, 155MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.02G/5.00G [00:26<00:12, 155MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/5.00G [00:26<00:14, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.06G/5.00G [00:26<00:20, 92.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/5.00G [00:27<00:23, 80.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.10G/5.00G [00:27<00:23, 82.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.11G/5.00G [00:27<00:22, 83.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/5.00G [00:27<00:17, 104MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.16G/5.00G [00:27<00:15, 116MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/5.00G [00:27<00:12, 143MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.21G/5.00G [00:28<00:11, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/5.00G [00:28<00:10, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.26G/5.00G [00:28<00:09, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/5.00G [00:28<00:09, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.30G/5.00G [00:28<00:09, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/5.00G [00:28<00:10, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/5.00G [00:28<00:10, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.37G/5.00G [00:28<00:10, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.40G/5.00G [00:29<00:09, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/5.00G [00:29<00:08, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.46G/5.00G [00:29<00:07, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/5.00G [00:29<00:07, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.51G/5.00G [00:29<00:07, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/5.00G [00:29<00:07, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.57G/5.00G [00:29<00:07, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/5.00G [00:30<00:06, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/5.00G [00:30<00:06, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.66G/5.00G [00:30<00:06, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/5.00G [00:30<00:06, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.71G/5.00G [00:30<00:09, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.73G/5.00G [00:30<00:08, 145MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.75G/5.00G [00:34<00:58, 21.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.80G/5.00G [00:34<00:34, 34.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/5.00G [00:34<00:24, 47.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.86G/5.00G [00:34<00:18, 62.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/5.00G [00:34<00:15, 71.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.92G/5.00G [00:35<00:10, 101MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.95G/5.00G [00:35<00:08, 123MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.98G/5.00G [00:35<00:07, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.02G/5.00G [00:35<00:06, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.05G/5.00G [00:35<00:05, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/5.00G [00:35<00:05, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.11G/5.00G [00:35<00:04, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/5.00G [00:36<00:04, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.17G/5.00G [00:36<00:04, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.19G/5.00G [00:36<00:04, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.22G/5.00G [00:36<00:04, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/5.00G [00:37<00:16, 45.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.27G/5.00G [00:38<00:11, 65.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/5.00G [00:38<00:08, 79.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.32G/5.00G [00:38<00:06, 101MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.35G/5.00G [00:38<00:05, 123MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.38G/5.00G [00:38<00:04, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.41G/5.00G [00:38<00:03, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/5.00G [00:38<00:03, 154MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.47G/5.00G [00:39<00:02, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.50G/5.00G [00:39<00:02, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.53G/5.00G [00:39<00:02, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.56G/5.00G [00:39<00:02, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.59G/5.00G [00:40<00:06, 66.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/5.00G [00:40<00:04, 87.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.66G/5.00G [00:40<00:03, 109MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/5.00G [00:41<00:02, 114MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.71G/5.00G [00:41<00:02, 124MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/5.00G [00:41<00:02, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.76G/5.00G [00:41<00:01, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.79G/5.00G [00:41<00:01, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.82G/5.00G [00:41<00:00, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.85G/5.00G [00:41<00:00, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.89G/5.00G [00:42<00:00, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.92G/5.00G [00:42<00:00, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.95G/5.00G [00:42<00:00, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 5.00G/5.00G [00:42<00:00, 117MB/s]\n",
            "Downloading shards:  50% 1/2 [00:42<00:42, 42.77s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/564M [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 21.0M/564M [00:00<00:02, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 52.4M/564M [00:00<00:02, 208MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 83.9M/564M [00:00<00:02, 215MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 115M/564M [00:00<00:02, 213MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 147M/564M [00:00<00:02, 207MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 178M/564M [00:00<00:01, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 210M/564M [00:00<00:01, 215MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 241M/564M [00:01<00:01, 216MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 273M/564M [00:01<00:01, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 304M/564M [00:01<00:01, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 336M/564M [00:01<00:00, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 367M/564M [00:08<00:13, 14.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 409M/564M [00:08<00:06, 22.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 440M/564M [00:08<00:04, 30.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 472M/564M [00:08<00:02, 40.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 503M/564M [00:08<00:01, 51.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 524M/564M [00:08<00:00, 61.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 545M/564M [00:09<00:00, 72.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 564M/564M [00:09<00:00, 61.3MB/s]\n",
            "Downloading shards: 100% 2/2 [00:52<00:00, 26.12s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:22<00:00, 11.49s/it]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 800kB/s]\n",
            "trainable params: 10,485,760 || all params: 2,790,169,600 || trainable%: 0.3758\n",
            "Model size: 5341.83 MB\n",
            "Trainable parameters: 10,485,760\n",
            "Validation disabled to save memory\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "\n",
            "Starting training with performance monitoring...\n",
            "Format: step | loss | iteration time | tokens per second | GPU memory\n",
            "\n",
            "README.md: 100% 10.2k/10.2k [00:00<00:00, 46.0MB/s]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loading `train_dataloader` to estimate number of stepping batches.\n",
            "Epoch 0: |          | 0/? [00:00<?, ?it/s] /content/training.py:179: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(dtype=torch.bfloat16, enabled=True):\n",
            "Epoch 0: |          | 40/? [01:55<00:00,  0.35it/s, v_num=0, train_loss_step=2.700]50 | loss: 3.4507 | 1.29s/it | 791.8 tokens/s | 8.99 GB\n",
            "Epoch 0: |          | 40/? [02:44<00:00,  0.24it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.990]`Trainer.fit` stopped: `max_epochs=1` reached.\n",
            "Epoch 0: |          | 40/? [06:12<00:00,  0.11it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.990]\n",
            "\n",
            "Training completed. Best model saved at: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "GQxR531KsWoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --model_path ./checkpoints/last.ckpt --base_model microsoft/phi-2 --example_prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3TXVgfz5aG9",
        "outputId": "39982970-5806-4646-b9e9-d8314e2f5bac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-07 07:18:23.647778: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741331903.690773    3292 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741331903.703082    3292 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-07 07:18:23.749847: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading tokenizer from microsoft/phi-2...\n",
            "Loading model from ./checkpoints/last.ckpt...\n",
            "Warning: The model path './checkpoints/last.ckpt' may not contain a valid HuggingFace model.\n",
            "Expected files not found. Available files in the directory:\n",
            "Error loading model: [Errno 20] Not a directory: './checkpoints/last.ckpt'\n",
            "\n",
            "Fallback: trying to load from base model path and merge with adapters...\n",
            "Loading checkpoint shards: 100% 2/2 [00:25<00:00, 12.80s/it]\n",
            "Using base model as fallback\n",
            "Model loaded successfully and moved to cuda!\n",
            "Using 5 example prompts\n",
            "\n",
            "Generating response for prompt 1/5\n",
            "Prompt: Write a short story about a robot learning to feel emotions....\n",
            "Generating:  88% 452/512 [04:27<00:35,  1.69it/s]\n",
            "Generated 452 tokens in 267.98s (1.69 tokens/sec)\n",
            "\n",
            "Generating response for prompt 2/5\n",
            "Prompt: Explain how nuclear fusion works in simple terms....\n",
            "Generating:   6% 33/512 [00:05<01:21,  5.88it/s]\n",
            "Generated 33 tokens in 5.61s (5.88 tokens/sec)\n",
            "\n",
            "Generating response for prompt 3/5\n",
            "Prompt: What are the ethical implications of artificial intelligence?...\n",
            "Generating:  13% 67/512 [00:12<01:24,  5.24it/s]\n",
            "Generated 67 tokens in 12.78s (5.24 tokens/sec)\n",
            "\n",
            "Generating response for prompt 4/5\n",
            "Prompt: Create a recipe for a delicious vegetarian pasta dish....\n",
            "Generating:  55% 281/512 [01:52<01:32,  2.50it/s]\n",
            "Generated 281 tokens in 112.33s (2.50 tokens/sec)\n",
            "\n",
            "Generating response for prompt 5/5\n",
            "Prompt: Write a poem about the changing seasons....\n",
            "Generating:  21% 105/512 [00:22<01:27,  4.64it/s]\n",
            "Generated 105 tokens in 22.62s (4.64 tokens/sec)\n",
            "\n",
            "Evaluation completed. Results saved to example_outputs.json\n",
            "\n",
            "Example outputs:\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions....\n",
            "Response: In the year 2050, robots were a common sight in the world. They were used for various purposes, such as cleaning, cooking, teaching, and even entertaining. However, there was one robot that stood out ...\n",
            "\n",
            "Prompt: Explain how nuclear fusion works in simple terms....\n",
            "Response: Nuclear fusion is a process that happens when two small atoms join together to make a bigger atom. This releases a lot of energy that we can use for power....\n",
            "\n",
            "Prompt: What are the ethical implications of artificial intelligence?...\n",
            "Response: In this lesson, we will explore the ethical implications of artificial intelligence. We will discuss the potential benefits and risks of AI, such as job displacement, privacy concerns, and biases in a...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "## Train QLoRA Adapters"
      ],
      "metadata": {
        "id": "GAxxE37pCinM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python training.py --max_epochs 1 --save_adapters_only"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s7_1PXX__aE",
        "outputId": "eed098af-dfcb-4569-cb47-cd7671efdbed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-07 07:26:12.208350: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741332372.235178    5282 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741332372.245135    5282 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-07 07:26:12.282816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "Found existing checkpoint: checkpoints/last.ckpt\n",
            "Resume training from checkpoint? (y/n): n\n",
            "Setting batch size to 1 to save memory\n",
            "Set gradient accumulation to 16\n",
            "Set dataloader workers to 0 (main process only)\n",
            "DeepSpeed not available - using standard training\n",
            "Enabling extreme memory saving options...\n",
            "Loading checkpoint shards: 100% 2/2 [00:25<00:00, 12.91s/it]\n",
            "trainable params: 10,485,760 || all params: 2,790,169,600 || trainable%: 0.3758\n",
            "Model size: 5341.83 MB\n",
            "Trainable parameters: 10,485,760\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "\n",
            "Starting training with performance monitoring...\n",
            "Format: step | loss | iteration time | tokens per second | GPU memory\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /content/checkpoints exists and is not empty.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loading `train_dataloader` to estimate number of stepping batches.\n",
            "Epoch 0: |          | 0/? [00:00<?, ?it/s] /content/training.py:179: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(dtype=torch.bfloat16, enabled=True):\n",
            "Epoch 0: |          | 40/? [02:19<00:00,  0.29it/s, v_num=1, train_loss_step=4.810, train_loss_epoch=3.150]`Trainer.fit` stopped: `max_epochs=1` reached.\n",
            "Epoch 0: |          | 40/? [06:12<00:00,  0.11it/s, v_num=1, train_loss_step=4.810, train_loss_epoch=3.150]\n",
            "Saving LoRA adapters only...\n",
            "LoRA adapters saved to adapters\n",
            "Tokenizer saved to adapters\n",
            "\n",
            "Training completed. Best model saved at: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference with QLoRA Adapters"
      ],
      "metadata": {
        "id": "FOiimvj8LT5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --model_path ./adapters --base_model microsoft/phi-2 --use_qlora --example_prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXDxZOFnFONc",
        "outputId": "ff24152a-ef36-467e-9485-d93ebf8a4457"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-07 07:35:17.051504: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741332917.076949    7608 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741332917.086063    7608 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-07 07:35:17.134696: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading tokenizer from microsoft/phi-2...\n",
            "Loading base model microsoft/phi-2...\n",
            "Using 4-bit quantization (QLoRA)\n",
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
            "Loading checkpoint shards: 100% 2/2 [00:23<00:00, 11.95s/it]\n",
            "Loading QLoRA adapters from ./adapters...\n",
            "Converting normalization layers to float32 for stability\n",
            "Model loaded successfully and moved to cuda!\n",
            "Using 5 example prompts\n",
            "\n",
            "Generating response for prompt 1/5\n",
            "Prompt: Write a short story about a robot learning to feel emotions....\n",
            "Fixing model dtype issues...\n",
            "Trying greedy decoding instead...\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Generated 100 tokens in 10.69s (9.36 tokens/sec)\n",
            "\n",
            "Generating response for prompt 2/5\n",
            "Prompt: Explain how nuclear fusion works in simple terms....\n",
            "Generated 50 tokens in 5.35s (9.35 tokens/sec)\n",
            "\n",
            "Generating response for prompt 3/5\n",
            "Prompt: What are the ethical implications of artificial intelligence?...\n",
            "Generated 78 tokens in 6.75s (11.56 tokens/sec)\n",
            "\n",
            "Generating response for prompt 4/5\n",
            "Prompt: Create a recipe for a delicious vegetarian pasta dish....\n",
            "Generated 197 tokens in 17.91s (11.00 tokens/sec)\n",
            "\n",
            "Generating response for prompt 5/5\n",
            "Prompt: Write a poem about the changing seasons....\n",
            "Generated 112 tokens in 9.89s (11.32 tokens/sec)\n",
            "\n",
            "Evaluation completed. Results saved to example_outputs.json\n",
            "\n",
            "Example outputs:\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions....\n",
            "Response: Once upon a time, there was a robot named Robby. Robby was designed to be helpful and efficient, but he lacked one important thing - emotions. One day, Robby's creator decided to give him a special gi...\n",
            "\n",
            "Prompt: Explain how nuclear fusion works in simple terms....\n",
            "Response: Nuclear fusion is the process of combining two light atoms, such as hydrogen, into a heavier atom, such as helium. This releases a lot of energy, which can be used to power devices like stars, nuclear...\n",
            "\n",
            "Prompt: What are the ethical implications of artificial intelligence?...\n",
            "Response: The ethical implications of artificial intelligence are vast and complex. AI has the potential to revolutionize industries and improve our lives in many ways, but it also raises concerns about privacy...\n"
          ]
        }
      ]
    }
  ]
}